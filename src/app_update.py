import streamlit as st
from rag.chain import LLMHandler, VectorDatabase, QuestionAnsweringChain
from rag.create_knowlegde import add_documents, add_docs_from_files
from data_manager.web_crawler import auto_crawl
import os
import time
from dotenv import load_dotenv
from pathlib import Path

parent_dir = Path(r"B:\PROJECTS\CHATBOT_EDUCATION\src\data_manager\vector_collections")
subdirs = [d.name for d in parent_dir.iterdir() if d.is_dir()]
# print(subdirs)

# Cáº¥u hÃ¬nh trang
st.set_page_config(page_title="ğŸğŸ’¬ Gemini Chatbot (Streaming)")
st.title("ğŸ’¬ Assitant AI")

# HÃ m khá»Ÿi táº¡o á»©ng dá»¥ng
def initialize_app(path_faiss_index=r"B:\PROJECTS\CHATBOT_EDUCATION\data_source\data\faiss_v3"):
    # Táº£i biáº¿n mÃ´i trÆ°á»ng
    load_dotenv(dotenv_path=r"B:\PROJECTS\CHATBOT_EDUCATION\.env.init")
    gemini_key = os.getenv("gemini_generate")

    # Khá»Ÿi táº¡o cÃ¡c thÃ nh pháº§n chá»‰ má»™t láº§n
    if "qa_chain" not in st.session_state:
        llm_handler = LLMHandler(model_name="gemini-1.5-flash", gemini_key=gemini_key)
        vector_db = VectorDatabase(path_faiss_index=path_faiss_index)
        qa_chain = QuestionAnsweringChain(
            llm_handler=llm_handler,
            vector_db=vector_db,
            num_docs=5,
            apply_rewrite=False,
            apply_rerank=False,
            date_impact=0.01
        )
        st.session_state.qa_chain = qa_chain

# HÃ m xÃ³a lá»‹ch sá»­ chat
def clear_chat_history():
    st.session_state.messages = [{"role": "assistant", "content": "Xin chÃ o! ÄÃ¢y lÃ  HaUI Chatbot, trá»£ lÃ½ Ä‘áº¯c lá»±c dÃ nh cho báº¡n! Báº¡n muá»‘n tÃ¬m kiáº¿m thÃ´ng tin vá» nhá»¯ng gÃ¬?"}]

def handle_local_file():
    """
    Xá»­ lÃ½ khi ngÆ°á»i dÃ¹ng chá»n táº£i file tá»« local
    """
    uploaded_file = st.file_uploader("Chá»n file dá»¯ liá»‡u cá»§a báº¡n!")
    if uploaded_file is not None:
        with st.spinner("Äang táº£i dá»¯ liá»‡u..."):
            try:
                # LÆ°u file vÃ o thÆ° má»¥c táº¡m
                UPLOAD_DIR = r"B:\PROJECTS\CHATBOT_EDUCATION\src\data_manager\raw_data"
                os.makedirs(UPLOAD_DIR, exist_ok=True)

                file_name = uploaded_file.name
                # file_name = os.path.splitext(uploaded_file.name)[0]
                file_path = os.path.join(UPLOAD_DIR, file_name)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # LÆ°u vÃ o faiss
                add_docs_from_files(file_name=file_name)
                st.success(f"ÄÃ£ táº£i dá»¯ liá»‡u thÃ nh cÃ´ng vÃ o collection '{file_name}'!")
                subdirs.append(file_name)
            except Exception as e:
                st.error(f"Lá»—i khi táº£i dá»¯ liá»‡u: {str(e)}")

def handle_url_input():
    """
    Xá»­ lÃ½ khi ngÆ°á»i dÃ¹ng chá»n crawl URL
    """
    collection_name = st.text_input(
        "TÃªn collection trong Faiss:", 
        "data_test",
        help="Nháº­p tÃªn collection báº¡n muá»‘n lÆ°u trong Faiss"
    )

    url = st.text_input("Nháº­p URL:", "https://www.stack-ai.com/docs")
    
    if st.button("Crawl dá»¯ liá»‡u"):
        if not collection_name:
            st.error("Vui lÃ²ng nháº­p tÃªn collection!")
            return
            
        with st.spinner("Äang crawl dá»¯ liá»‡u..."):
            try:
                auto_crawl(url, collection_name, 2, 2)
                add_documents(file_name=collection_name)
                st.success(f"ÄÃ£ crawl dá»¯ liá»‡u thÃ nh cÃ´ng vÃ o collection '{collection_name}'!")
            except Exception as e:
                st.error(f"Lá»—i khi crawl dá»¯ liá»‡u: {str(e)}")
    subdirs.append(collection_name)
# Sidebar
with st.sidebar:
    with st.sidebar:
        tabs = st.tabs(["ğŸ’¬ Chatbot", "âš™ï¸ CÃ i Ä‘áº·t", "â„¹ï¸ ThÃ´ng tin"])

    with tabs[0]:
        # st.title("ğŸğŸ’¬ AI Assistant")
        st.write("Xin chÃ o! MÃ¬nh lÃ  AI Assistant. GiÃºp báº¡n giáº£i Ä‘Ã¡p tháº¯c máº¯c, tra cá»©u thÃ´ng tin má»™t cÃ¡ch nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c nháº¥t!")
        # st.divider()
        st.header("ğŸ“š Nguá»“n dá»¯ liá»‡u")
        data_source = st.radio(
            "CÃ¡c nguá»“n giÃºp Assistant Ä‘Æ°a ra cÃ¢u tráº£ lá»i dá»±a trÃªn nhá»¯ng thÃ´ng tin quan trá»ng nháº¥t Ä‘á»‘i vá»›i báº¡n.",
            ["File Local", "URL trá»±c tiáº¿p"]
        )

        if data_source == "File Local":
            handle_local_file()
        else:
            handle_url_input()

        subdirs = [d.name for d in parent_dir.iterdir() if d.is_dir()]
        st.divider()
        st.header("Chá»n cÆ¡ sá»Ÿ tri thá»©c")
        vector_source = st.radio(
            "Chá»n cÆ¡ sá»Ÿ tri thá»©c báº¡n muá»‘n sá»­ dá»¥ng:",
            subdirs
        )
        # print(vector_source)
        path_faiss_index = os.path.join(r"B:\PROJECTS\CHATBOT_EDUCATION\src\data_manager\vector_collections", 
                            f"{vector_source}")
        print(path_faiss_index)

        if st.button('Khá»Ÿi táº¡o á»©ng dá»¥ng'):
            initialize_app(path_faiss_index=path_faiss_index)
        st.button('ğŸ§¹ XÃ³a lá»‹ch sá»­ Chat', on_click=clear_chat_history)

    with tabs[1]:
        st.write("Báº¡n cÃ³ thá»ƒ tÃ¹y chá»‰nh cÃ¡c thiáº¿t láº­p táº¡i Ä‘Ã¢y (Ä‘ang phÃ¡t triá»ƒn).")
        st.divider()
        st.button('Khá»Ÿi táº¡o cÃ³ sáºµn', on_click=initialize_app)

    with tabs[2]:
        st.subheader("â„¹ï¸ ThÃ´ng tin")
        st.markdown("""
        **TÃªn dá»± Ã¡n:** Chatbot há»— trá»£ tuyá»ƒn sinh HaUI  
        **PhiÃªn báº£n:** 1.0  
        **MÃ´ hÃ¬nh ngÃ´n ngá»¯:** [gemini-1.5-flash](https://ai.google.dev/gemini)    
        **MÃ´ hÃ¬nh embedding:** [hiieu/halong_embedding](https://huggingface.co/hiieu/halong_embedding)   
        **MÃ´ hÃ¬nh xáº¿p háº¡ng láº¡i:** [namdp-ptit/ViRanker](https://huggingface.co/namdp-ptit/ViRanker)   
        **TÃ¡c giáº£:** Lam Hoang  
        ğŸ“§ Email: hpl114p@gmail.com  
        ğŸ“… Cáº­p nháº­t láº§n cuá»‘i: 26/06/2025
        """)
        st.divider()

        st.markdown("### ğŸ¤– Chatbot hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?")
        st.markdown("""
        Chatbot hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch tá»« cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng, sá»­ dá»¥ng ká»¹ thuáº­t tÃ¬m vÄƒn báº£n liÃªn quan Ä‘áº¿n cÃ¢u há»i trong bá»™ dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c vector hÃ³a (text similarity) vÃ  lÆ°u trá»¯ thÃ´ng qua vector database. 
        Nhá»¯ng Ä‘oáº¡n vÄƒn báº£n liÃªn quan sáº½ Ä‘Æ°á»£c trÃ­ch xuáº¥t vÃ  Ä‘Æ°a vÃ o mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘á»ƒ sinh ra cÃ¢u tráº£ lá»i phÃ¹ há»£p.
        """)

        st.markdown("### ğŸ“Œ CÃ¡ch sá»­ dá»¥ng chatbot Ä‘á»ƒ tra cá»©u thÃ´ng tin")
        st.markdown("""
        Äá»ƒ sá»­ dá»¥ng chatbot hiá»‡u quáº£, báº¡n nÃªn Ä‘áº·t cÃ¢u há»i rÃµ rÃ ng vÃ  Ä‘áº§y Ä‘á»§ Ä‘á»ƒ mÃ´ hÃ¬nh hiá»ƒu Ä‘Ãºng yÃªu cáº§u vÃ  Ä‘Æ°a ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c.
        Tuy nhiÃªn, má»™t sá»‘ cÃ¢u tráº£ lá»i cÃ³ thá»ƒ chÆ°a chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i, báº¡n nÃªn kiá»ƒm chá»©ng thÃ´ng tin hoáº·c liÃªn há»‡ há»— trá»£ náº¿u cáº§n.
        """)

        st.markdown("### â“ ThÃ´ng tin tá»« chatbot cÃ³ Ä‘Ã¡ng tin cáº­y khÃ´ng?")
        st.markdown("""
        VÃ¬ chatbot lÃ  má»™t mÃ´ hÃ¬nh xÃ¡c suáº¥t, nÃªn váº«n cÃ³ kháº£ nÄƒng cung cáº¥p thÃ´ng tin khÃ´ng chÃ­nh xÃ¡c trong má»™t sá»‘ trÆ°á»ng há»£p. 
        HÃ£y kiá»ƒm chá»©ng thÃ´ng tin trÆ°á»›c khi sá»­ dá»¥ng hoáº·c liÃªn há»‡ há»— trá»£ Ä‘á»ƒ Ä‘Æ°á»£c giáº£i Ä‘Ã¡p chÃ­nh xÃ¡c nháº¥t.
        """)


if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Xin chÃ o! ÄÃ¢y lÃ  Asistant AI, trá»£ lÃ½ Ä‘áº¯c lá»±c dÃ nh cho báº¡n! Báº¡n muá»‘n tÃ¬m kiáº¿m thÃ´ng tin vá» nhá»¯ng gÃ¬?"}]

# Hiá»ƒn thá»‹ lá»‹ch sá»­ há»™i thoáº¡i
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if user_input := st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n táº¡i Ä‘Ã¢y..."):
    # Hiá»ƒn thá»‹ ngay trÃªn giao diá»‡n
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input}) 

    # Xá»­ lÃ½ truy váº¥n
    response, links = st.session_state.qa_chain.run(user_input)

    print("---------------------------------------------")
    print(links)
    # Hiá»ƒn thá»‹ pháº£n há»“i
    with st.chat_message("assistant"):
        # st.markdown(response)
        response_placeholder = st.empty()
        displayed_text = ""
        for chunk in response.split():
            displayed_text += chunk + " "
            response_placeholder.markdown(displayed_text + "â–Œ")
            time.sleep(0.05)  # Ä‘iá»u chá»‰nh tá»‘c Ä‘á»™ hiá»ƒn thá»‹
        response_placeholder.markdown(displayed_text)  # xoÃ¡ dáº¥u â–Œ cuá»‘i cÃ¹ng

        with st.expander("ğŸ”— Nguá»“n tham kháº£o (nháº¥n Ä‘á»ƒ xem)"):
            for i, link in enumerate(links, 1):
                st.markdown(f"{i}. [{link}]({link})")
        
    # LÆ°u vÃ o lá»‹ch sá»­
    st.session_state.messages.append({"role": "assistant", "content": response})