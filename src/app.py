import streamlit as st
import os
import time
from dotenv import load_dotenv
# from pyngrok import ngrok

# public_url = ngrok.connect(port = '80')
# print(f"Please click on the text below {public_url}")

# Táº£i biáº¿n mÃ´i trÆ°á»ng
load_dotenv(dotenv_path=r"B:\PROJECTS\CHATBOT_EDUCATION\.env.init")
gemini_key = os.getenv("gemini_key")

# Import cÃ¡c thÃ nh pháº§n tá»« chain.py
from rag.chain import LLMHandler, VectorDatabase, QuestionAnsweringChain

# Cáº¥u hÃ¬nh trang
st.set_page_config(page_title="ğŸğŸ’¬ Gemini Chatbot (Streaming)")
st.title("ğŸğŸ’¬ Assitant AI")

# HÃ m xÃ³a lá»‹ch sá»­ chat
def clear_chat_history():
    st.session_state.messages = [{"role": "assistant", "content": "Xin chÃ o! ÄÃ¢y lÃ  HaUI Chatbot, trá»£ lÃ½ Ä‘áº¯c lá»±c dÃ nh cho báº¡n! Báº¡n muá»‘n tÃ¬m kiáº¿m thÃ´ng tin vá» nhá»¯ng gÃ¬?"}]
    # st.session_state.chat_history = []
    # st.session_state.references = []


# Sidebar
with st.sidebar:
    with st.sidebar:
        tabs = st.tabs(["ğŸ’¬ Assitant", "âš™ï¸ CÃ i Ä‘áº·t", "â„¹ï¸ ThÃ´ng tin"])

    with tabs[0]:
        st.title("ğŸğŸ’¬ Assitant AI")
        st.write("Xin chÃ o! MÃ¬nh lÃ  Assitant AI. GiÃºp báº¡n giáº£i Ä‘Ã¡p tháº¯c máº¯c, tra cá»©u thÃ´ng tin má»™t cÃ¡ch nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c nháº¥t!")
        st.button('ğŸ§¹ XÃ³a lá»‹ch sá»­ Chat', on_click=clear_chat_history)

    with tabs[1]:
        st.write("Báº¡n cÃ³ thá»ƒ tÃ¹y chá»‰nh cÃ¡c thiáº¿t láº­p táº¡i Ä‘Ã¢y (Ä‘ang phÃ¡t triá»ƒn).")

    with tabs[2]:
        st.subheader("â„¹ï¸ ThÃ´ng tin")
        st.markdown("""
        **TÃªn dá»± Ã¡n:** Chatbot há»— trá»£ tuyá»ƒn sinh HaUI  
        **PhiÃªn báº£n:** 1.0  
        **MÃ´ hÃ¬nh ngÃ´n ngá»¯:** [gemini-1.5-flash](https://ai.google.dev/gemini)    
        **MÃ´ hÃ¬nh embedding:** [hiieu/halong_embedding](https://huggingface.co/hiieu/halong_embedding)   
        **MÃ´ hÃ¬nh xáº¿p háº¡ng láº¡i:** [namdp-ptit/ViRanker](https://huggingface.co/namdp-ptit/ViRanker)   
        **TÃ¡c giáº£:** Lam Hoang  
        ğŸ“§ Email: hpl114p@gmail.com  
        ğŸ“… Cáº­p nháº­t láº§n cuá»‘i: 26/06/2025
        """)
        st.divider()

        st.markdown("### ğŸ¤– Chatbot hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?")
        st.markdown("""
        Chatbot hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch tá»« cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng, sá»­ dá»¥ng ká»¹ thuáº­t tÃ¬m vÄƒn báº£n liÃªn quan Ä‘áº¿n cÃ¢u há»i trong bá»™ dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c vector hÃ³a (text similarity) vÃ  lÆ°u trá»¯ thÃ´ng qua vector database. 
        Nhá»¯ng Ä‘oáº¡n vÄƒn báº£n liÃªn quan sáº½ Ä‘Æ°á»£c trÃ­ch xuáº¥t vÃ  Ä‘Æ°a vÃ o mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘á»ƒ sinh ra cÃ¢u tráº£ lá»i phÃ¹ há»£p.
        """)

        st.markdown("### ğŸ“Œ CÃ¡ch sá»­ dá»¥ng chatbot Ä‘á»ƒ tra cá»©u thÃ´ng tin")
        st.markdown("""
        Äá»ƒ sá»­ dá»¥ng chatbot hiá»‡u quáº£, báº¡n nÃªn Ä‘áº·t cÃ¢u há»i rÃµ rÃ ng vÃ  Ä‘áº§y Ä‘á»§ Ä‘á»ƒ mÃ´ hÃ¬nh hiá»ƒu Ä‘Ãºng yÃªu cáº§u vÃ  Ä‘Æ°a ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c.
        Tuy nhiÃªn, má»™t sá»‘ cÃ¢u tráº£ lá»i cÃ³ thá»ƒ chÆ°a chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i, báº¡n nÃªn kiá»ƒm chá»©ng thÃ´ng tin hoáº·c liÃªn há»‡ há»— trá»£ náº¿u cáº§n.
        """)

        st.markdown("### â“ ThÃ´ng tin tá»« chatbot cÃ³ Ä‘Ã¡ng tin cáº­y khÃ´ng?")
        st.markdown("""
        VÃ¬ chatbot lÃ  má»™t mÃ´ hÃ¬nh xÃ¡c suáº¥t, nÃªn váº«n cÃ³ kháº£ nÄƒng cung cáº¥p thÃ´ng tin khÃ´ng chÃ­nh xÃ¡c trong má»™t sá»‘ trÆ°á»ng há»£p. 
        HÃ£y kiá»ƒm chá»©ng thÃ´ng tin trÆ°á»›c khi sá»­ dá»¥ng hoáº·c liÃªn há»‡ há»— trá»£ Ä‘á»ƒ Ä‘Æ°á»£c giáº£i Ä‘Ã¡p chÃ­nh xÃ¡c nháº¥t.
        """)
    
# Khá»Ÿi táº¡o phiÃªn chatbot náº¿u chÆ°a cÃ³
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Xin chÃ o! ÄÃ¢y lÃ  HaUI Chatbot, trá»£ lÃ½ Ä‘áº¯c lá»±c dÃ nh cho báº¡n! Báº¡n muá»‘n tÃ¬m kiáº¿m thÃ´ng tin vá» nhá»¯ng gÃ¬?"}]

# Khá»Ÿi táº¡o cÃ¡c thÃ nh pháº§n chá»‰ má»™t láº§n
if "qa_chain" not in st.session_state:
    llm_handler = LLMHandler(model_name="gemini-1.5-flash", gemini_key=gemini_key)
    vector_db = VectorDatabase(path_faiss_index=r"B:\PROJECTS\CHATBOT_EDUCATION\data_source\data\faiss_v3")
    qa_chain = QuestionAnsweringChain(
        llm_handler=llm_handler,
        vector_db=vector_db,
        num_docs=5,
        apply_rewrite=False,
        apply_rerank=False,
        date_impact=0.01
    )
    st.session_state.qa_chain = qa_chain

# Hiá»ƒn thá»‹ lá»‹ch sá»­ há»™i thoáº¡i
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Nháº­n Ä‘áº§u vÃ o tá»« ngÆ°á»i dÃ¹ng
if user_input := st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n táº¡i Ä‘Ã¢y..."):
    # Hiá»ƒn thá»‹ ngay trÃªn giao diá»‡n
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Xá»­ lÃ½ truy váº¥n
    response, links = st.session_state.qa_chain.run(user_input)

    print("---------------------------------------------")
    print(links)
    # Hiá»ƒn thá»‹ pháº£n há»“i
    with st.chat_message("assistant"):
        # st.markdown(response)
        response_placeholder = st.empty()
        displayed_text = ""
        for chunk in response.split():
            displayed_text += chunk + " "
            response_placeholder.markdown(displayed_text + "â–Œ")
            time.sleep(0.05)  # Ä‘iá»u chá»‰nh tá»‘c Ä‘á»™ hiá»ƒn thá»‹
        response_placeholder.markdown(displayed_text)  # xoÃ¡ dáº¥u â–Œ cuá»‘i cÃ¹ng

        with st.expander("ğŸ”— Nguá»“n tham kháº£o (nháº¥n Ä‘á»ƒ xem)"):
            for i, link in enumerate(links, 1):
                st.markdown(f"{i}. [{link}]({link})")
        
    # LÆ°u vÃ o lá»‹ch sá»­
    st.session_state.messages.append({"role": "assistant", "content": response})
